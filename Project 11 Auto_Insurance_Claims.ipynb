{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the claim amount from and automobile insurance set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ds=pd.read_csv('Auto_Insurance_Claims_amount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and treat null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ds.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscor=ds.corr()\n",
    "sns.heatmap(dscor, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the columns that correlate best with the target column are:\n",
    "    Monthly Premium Auto, Total claim amount.  Will check again after encoding the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is very large in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "ds['Claim Amount'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some outliers present, but not extreme ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the amount of entries per response type\n",
    "ds.groupby('Response')['Response'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(ds['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Far more claims were rejected than granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Response', y= 'Claim Amount', hue='Coverage', data=ds, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of coverage affects the amounts that people claim for proportionally. It does not reflect in the amounts that are approved though. The Basic and Extended coverages have very similar claims amounts that are approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Response', y= 'Total Claim Amount', hue='Coverage', data=ds, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total claim amounts reflect the coverage levels proportionally. It does not seem to affect the approval of claims otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Response', y= 'Monthly Premium Auto', hue='Coverage', data=ds, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher monthly payments generally lead to greater claim approval rates except for the Basic coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Response', y= 'Monthly Premium Auto', hue='Gender', data=ds, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females who have their claims approved seem to pay a noticibly higher monthly premium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical columns to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds=ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change categorical data to numerical data for 2 categoriacl columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "cols=['State','Response', 'Coverage', 'Education','Effective To Date',\n",
    "       'EmploymentStatus', 'Gender', 'Location Code',\n",
    "       'Marital Status', 'Policy Type', 'Policy', 'Claim Reason',\n",
    "       'Sales Channel', 'Vehicle Class', 'Vehicle Size']\n",
    "for col in cols:\n",
    "    eds[col] = le.fit_transform(eds[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlation after encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscor=eds.corr()\n",
    "sns.heatmap(dscor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strongest correlation to target column:\n",
    "    Total Claim Amount, Monthly Premium Auto, Coverage\n",
    "Most are somewhat correlating.\n",
    "Claim Reason has the poorest correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant (poorly correlated) columns - dataset renamed to nds (new dataset)\n",
    "nds=ds.drop(columns=['Customer', 'Country', 'State Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show boxplots for all columns, check outliers\n",
    "collist=nds.columns.values\n",
    "ncol=23\n",
    "nrows=10\n",
    "\n",
    "plt.figure(figsize=(ncol,5*ncol))\n",
    "for i in range(1, len(collist)):\n",
    "    plt.subplot(nrows,ncol,i+1)\n",
    "    sns.boxplot(nds[collist[i]], color='red', orient='v')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers - dataset renamed to cds (clean dataset)\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_score=abs(zscore(nds))\n",
    "print(nds.shape)\n",
    "cds=nds.loc[(z_score<3).all(axis=1)]\n",
    "print(cds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and adjust skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show skewness (less than 0.55 is ok)\n",
    "cds.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat skewness using log\n",
    "for col in cds.columns:\n",
    "    if cds.skew().loc[col]>0.55:\n",
    "        cds[col]=np.log1p(cds[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineup target and input values\n",
    "cds_x=cds.drop(columns=['Claim Amount'])\n",
    "y=cds[['Claim Amount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling for linear regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(cds_x)\n",
    "x=pd.DataFrame(x,columns=cds_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y, random_state=55, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error calculation\n",
    "max_r_score=0\n",
    "for r_state in range(42,100):\n",
    "    x_train,x_test, y_train, y_test = train_test_split(x,y, random_state=r_state, test_size=0.20)\n",
    "    regr=linear_model.LinearRegression()\n",
    "    regr.fit(x_train,y_train)\n",
    "    y_pred=regr.predict(x_test)\n",
    "    r2_scr=r2_score(y_test,y_pred)\n",
    "    if r2_scr>max_r_score:\n",
    "        max_r_score=r2_scr\n",
    "        final_r_state=r_state\n",
    "print(\"Max r2 score for\",final_r_state,\"is\", max_r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossvalidation\n",
    "cross_val_score(linear_model.LinearRegression(),x,y,cv=10,scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 score gives us a rondom state of 71\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y, random_state=71, test_size=0.20)\n",
    "lreg=linear_model.LinearRegression()\n",
    "lreg.fit(x_train,y_train)\n",
    "y_pred=lreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 and Mean squared error statements\n",
    "print('r score is: ',r2_score(y_test,y_pred))\n",
    "print('RMSE is: ', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for SVR types\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "kernellist=['linear','poly','rbf']\n",
    "for i in kernellist:\n",
    "    sv=SVR(kernel=i)\n",
    "    sv.fit(x_train,y_train)\n",
    "    print(sv.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "# Prepare a range of alpha values to test\n",
    "alphavalue={'alpha':[1,0.1,0.01,0.001,0.0001,0]}\n",
    "# Create and fit a Ridge regression model to test each alpha\n",
    "model=Ridge()\n",
    "grid=GridSearchCV(estimator=model,param_grid=alphavalue)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "#Summarize the results of the grid search\n",
    "\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a Ridge regression model to test each alpha\n",
    "model2=Lasso()\n",
    "grid=GridSearchCV(estimator=model2,param_grid=alphavalue)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "#Summarize the results of the grid search\n",
    "\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train, y_test\n",
    "# Try to minimize the coefficient variance\n",
    "\n",
    "rd=Ridge(alpha=1)\n",
    "rd.fit(x_train,y_train)\n",
    "rd.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score for Ridge Regressor\n",
    "cross_val_score(linear_model.Ridge(alpha=1),x,y,cv=10,scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train, y_test\n",
    "# Try to minimize the coefficient variance\n",
    "\n",
    "las=Lasso(alpha=0.001)\n",
    "las.fit(x_train,y_train)\n",
    "las.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gradient Boosting technique with GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr=GradientBoostingRegressor()\n",
    "parameters={'learning_rate':[0.001,0.01,0.1,1],'n_estimators':[10,100,500,1000]}\n",
    "clf=GridSearchCV(gbr,parameters, cv=5)\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CrossValScore with Gradient Boosting to check r2 mean and standard deviation\n",
    "print('Mean r2 score for GradientBoosting Regression:', cross_val_score(gbr,x,y,cv=5,scoring='r2').mean())\n",
    "print('Standard deviation in r2 score for GradientBoosting Regression:',cross_val_score(gbr,x,y,cv=5,scoring='r2').std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose the  GradientBoosting Regression model because it has the best scores.\n",
    "Mean r2 score: 91.4\n",
    "Standard deviation in r2 score : 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model as a pickle file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gbr,'Claims.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and use model to make a prediction\n",
    "model=joblib.load('Claims.plk')\n",
    "model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
